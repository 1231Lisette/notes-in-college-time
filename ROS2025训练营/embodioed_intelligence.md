# def

Embodied AI：通过“身体”与环境交互，实现感知-决策-行动闭环的智能体

- 身体是接口

学习不是在“纯信息空间”，而是靠身体与环境互动中获取反馈、积累经验

- 环境共进化

policy不是预设好的，机器人在“做事情的过程中”不断学习和调整

- 多模态具身

它的认知体系没有脱离身体的mind，正如没有脱离现实的intelligence。物理世界规则等多种信息要同时处理感知、动作、语言

# 算法发展趋势

![](images\image22.png)

![](images\image23.png)
![](images\image24.png)
![](images\image25.png)
![](images\image26.png)
![](images\image27.png)
![](images\image28.png)
![](images\image29.png)
![](images\image30.png)
![](images\image31.png)
![](images\image32.png)
![](images\image33.png)
![](images\image34.png)
![](images\image35.png)
![](images\image36.png)
![](images\image37.png)
![](images\image38.png)
![](images\image39.png)
![](images\image40.png)
![](images\image41.png)
![](images\image42.png)
![](images\image43.png)
![](images\image44.png)
![](images\image45.png)
![](images\image46.png)
![](images\image47.png)
![](images\image48.png)
![](images\image49.png)

# attention

# LLM

# VLM

# VLN

# VLA

- 可靠性和可执行性
- 感知和物理世界的不确定性
- 传统 LLM/VLM 是「一次性输出」，并不与环境交互或考虑实时反馈。VLA要求机器人在执行过程中根据传感器反馈、错误、环境变化实时调整动作(闭环控制loop)
- 行为与场景的安全性



| 项目    | 数据构建                                          | 模型训练                                            | 适用场景                                 | 控制效果                                      |                        存在问题                        |
| ------- | ------------------------------------------------- | --------------------------------------------------- | ---------------------------------------- | --------------------------------------------- | :----------------------------------------------------: |
| RT1     | 封闭数据（130k + 机器人收集示范）                 | 从 scratch 训练 Transformer policy                  | 适用于机器人 mobile manipulation         | 连续控制效果较好，低延迟高频                  |    封闭数据无法复现；泛化到新任务能力弱；无语言接口    |
| RT2     | 封闭数据 + 网络图文数据                           | 基于 PaLM-E 微调语言提示 + 图片输入→动作 token 输出 | 适用于 open-set 指令任务（语言泛化好）   | 泛化表现优于 RT1；动作较平滑                  |     模型闭源，训练代价高；动作空间离散化后精度损失     |
| OCTO    | 开源数据集（多源数据）                            | 支持从公开模型微调（如 PaLI-X）或 Octo-Llama 变体   | 支持多平台部署、适用于复杂组合任务       | 控制粒度较粗，适用于长时任务结构预测          |     动作输出为 high-level subgoal（需另接控制器）      |
| OpenVLA | 开源数据 pipeline开源示范采集器、数据构建格式清晰 | 微调已有 VLM 模型（如 SigLIP）结合 policy head      | 支持开放式语言任务，泛化强，适合研究使用 | 控制效果依赖后处理，适用于 mid-level 动作生成 |         动作分辨率偏低；缺乏对高频控制任务支持         |
| OpenPI  | 自构建数据集，强调，少数据泛化                    | 基于 Pre-Trained VLM 微调                           | 灵巧手 / 机械臂控制，适合轻量系统验证    | 控制响应平稳，泛化依赖 engineering            | 效果依赖自构建数据集质量，向其他平台及任务泛化效果存疑 |

---



| 项目    | 数据构建要求                                         | Fine-tune 难度                                               | 适用任务场景                                  | 真机迁移难度                                         | 控制方式                                    |
| ------- | ---------------------------------------------------- | ------------------------------------------------------------ | --------------------------------------------- | ---------------------------------------------------- | ------------------------------------------- |
| RT1     | 高：需要大规模机器人数据，闭源采集策略不公开         | 高：模型不开源，需复刻复杂 transformer，平台耦合             | /                                             | 高：与 Google 平台强绑定，迁移困难                   | 6D 连续动作，高频控制                       |
| RT2     | 高：融合图文数据 + 机器人数据，训练集构建难度大      | 高：依赖 PaLM-E 模型，闭源不可复现                           | /                                             | 极高：不易对接自己的平台和动作空间                   | 动作 token 序列（离散）                     |
| OCTO    | 中等：有数据构建工具 OctoGen，支持多种数据源拼接     | 中等：需熟悉 HuggingFace + VLM + subgoal policy 微调         | 多平台、多模态泛化任务，zero-shot combination | 中等：subgoal 需要额外控制器接口                     | 输出高层 subgoal，控制需接 backend          |
| OpenVLA | ✅ 低门槛：有数据采集框架，支持 egocentric + 语言指令 | ✅ 低～中等：基于现有 VLM（如 SigLIP）微调，开源透明          | 泛化语言指令类任务，自定义平台容易适配        | ✅ 中等偏低：动作头自定义性高，适配自己控制系统较容易 | mid-level 动作 token，可自定义控制频率      |
| OpenPI  | ✅ 灵活：支持少量自定义演示进行行为泛化，构建成本低   | ✅ 低～中等：支持自定义小模型训练结构简洁，能快速验证自有想法 | 为桌面级机械臂的多任务泛化控制设计            | ✅ 中等，适合有一定控制与感知经验的研究人员           | 语言 + RGB 图像→end-to-end 预测 6D 姿态目标 |



# Challenges & Future Directions 

- **高成本与复杂性的数据采集**  收集高质量、跨模态、动作层级丰富的数据集具有高昂成本，仍是限制VLA模型扩展的重要瓶颈。 
- **仅依赖视觉是否足够？**  视觉虽为主流 modality，但面对遮挡、模糊、细节丢失等问题时仍显不足，引发对多模态融合（如触觉、语言先验）的探讨。 
- **机器人系统的安全性保障不足**  当前大模型在未知环境中生成动作缺乏物理约束，容易造成危险操作，尤其在真实硬件执行中存在极大风险。 
- **Sim2Real 与 domain gap 问题**  尽管合成数据可快速生成大规模样本，但模拟与真实环境之间存在现实差距，导致迁移能力受限。 
- **长时间任务建模能力有限**  多数模型只擅长短时目标达成，缺乏规划性与分阶段记忆处理，难以完成复杂多步任务。
-  -**泛化能力不足 & 动作多样性差**  对新环境、新对象、新任务的泛化能力不强，动作输出单一，难以处理多模态、多策略并存的操作。



# 端到端策略

![13](images\image13.png)

优点：鲁棒

缺点：需要很多的数据进行训练；泛化性很弱



泛化性研究——基于数据规模驱动

马的人家google的deepmind，有个数据工厂，雇佣了100个工人，每天采集。。。采集了20万条真机数据。。。。     

![14](images\image14.png)

用计算资源来换数据！！！

![16](images\image16.png)

![17](images\image17.png)

![17](images\image18.png)

![17](images\image18.png)

![17](images\image20.png)

 