# 1205

模仿学习在LLM上效果很好，为什么VLA上却总是翻车？

- 核心原因是**误差累计**

文本生成是模型预测下一个token，就算预测错了一个词，后面生成的空间还是

很大，模型可以自己圆回来，再加上训练数据里各种各样的句子里面都有，模型见多识广，这样的误差就被稀释了

---

但是机器人操作不是，比如要拿起一个杯子，手的位置偏离了1cm，下一步就会更偏，误差就会越滚越大，最后任务就失败了，而且训练数据里面全是正确的轨迹，它也学不到错误的时候哦该怎么办？

---

$$\pi 0.6$$就解决了这个问题

pi团队提出了一个Rrcap的训练框架

核心思想就是不仅从“好”的数据里面学，也从坏的数据里面学

---

# 1206

1. 关盒子任务
2. 抓取不同颜色的物体

我的盒子是一个四面都有不同元素的茶盒

物体1选择之前3d打印课上打的哔哩哔哩

