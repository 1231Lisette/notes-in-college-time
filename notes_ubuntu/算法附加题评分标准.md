## 评分标准（总分 100 分）

### 一、基础部分（70 分）

1. **数据加载与理解（10 分）**  
   - 正确加载数据，并能简单描述（样本数、特征、类别）。  

2. **数据可视化（10 分）**  
   - 至少绘制一张散点图/箱线图。  
   - 图表清晰、能体现数据规律。  

3. **数据预处理（10 分）**  
   - 正确划分训练集与测试集。  
   - 代码可运行无报错。  

4. **模型训练（20 分）**  
   - 至少实现一种分类模型（如 KNN / 决策树 / 逻辑回归）。  
   - 在测试集上输出准确率。  

5. **结果总结（20 分）**  
   - 对结果有简要描述（准确率多少，效果如何）。  
   - 能指出某些特征对分类可能有帮助。  

---

### 二、加分部分（30 分）

1. **多模型比较（10 分）**  
   - 尝试 2 种以上的模型，并比较准确率。  

2. **可视化提升（5 分）**  
   - 使用混淆矩阵、决策边界等更直观的图。  

3. **模型优化（10 分）**  
   - 使用标准化/归一化/交叉验证。  
   - 或者用 `Pipeline` 管理流程。  

4. **报告完整性（5 分）**  
   - 代码有注释，结果展示清晰。  
   - 总结有逻辑，而不是简单复制输出结果。  

---

好的 👍。我们可以根据你刚刚定的评分标准，把不同“等级”的代码示例设计出来：

- **基础达标版（60-70分）**：能跑通、结果正确，但比较简陋。
- **中等提升版（75-85分）**：有基本可视化，多模型比较。
- **优秀完整版（90-100分）**：包含预处理、混淆矩阵、交叉验证、注释完整。

我给你写三份示例代码（都用 Iris 数据集，难度逐步增加）：

------

## 🟢 基础达标版（60-70 分）

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

# 1. 加载数据
iris = load_iris()
X, y = iris.data, iris.target

# 2. 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. 建立模型并训练
model = KNeighborsClassifier()
model.fit(X_train, y_train)

# 4. 评估模型
accuracy = model.score(X_test, y_test)
print("模型准确率:", accuracy)
```

👉 特点：能跑通，输出准确率，但没有可视化、没有总结。

------

## 🟡 中等提升版（75-85 分）

```python
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

# 1. 加载数据
iris = load_iris()
X, y = iris.data, iris.target

# 2. 数据可视化（花瓣长度 vs 花瓣宽度）
plt.figure(figsize=(6, 4))
sns.scatterplot(x=X[:, 2], y=X[:, 3], hue=iris.target_names[y])
plt.xlabel("Petal length")
plt.ylabel("Petal width")
plt.title("鸢尾花数据分布")
plt.show()

# 3. 划分数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. 模型对比
models = {
    "KNN": KNeighborsClassifier(),
    "DecisionTree": DecisionTreeClassifier()
}

for name, model in models.items():
    model.fit(X_train, y_train)
    print(f"{name} 准确率: {model.score(X_test, y_test):.2f}")
```

👉 特点：有可视化，有两个模型对比，但还缺少更深入的分析（如混淆矩阵）。

------

## 🔴 优秀完整版（90-100 分）

```python
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

# 1. 加载数据
iris = load_iris()
X, y = iris.data, iris.target

# 2. 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. 使用 Pipeline + 标准化 + 模型
pipelines = {
    "KNN": Pipeline([("scaler", StandardScaler()), ("knn", KNeighborsClassifier(n_neighbors=5))]),
    "SVM": Pipeline([("scaler", StandardScaler()), ("svm", SVC(kernel="linear"))])
}

for name, pipe in pipelines.items():
    pipe.fit(X_train, y_train)
    acc = pipe.score(X_test, y_test)
    print(f"{name} 测试集准确率: {acc:.2f}")
    
    # 交叉验证
    scores = cross_val_score(pipe, X, y, cv=5)
    print(f"{name} 平均交叉验证准确率: {scores.mean():.2f}")

# 4. 混淆矩阵展示（以 SVM 为例）
y_pred = pipelines["SVM"].predict(X_test)
cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)
disp.plot(cmap=plt.cm.Blues)
plt.title("SVM 混淆矩阵")
plt.show()
```

👉 特点：

- 使用了 `Pipeline` 和标准化。
- 多模型比较。
- 交叉验证。
- 混淆矩阵可视化。
- 注释清晰、结构完整。

------

要不要我帮你把这三份代码也打包成 **Markdown/PDF 作业参考示例**，直接给助教或评分员用？