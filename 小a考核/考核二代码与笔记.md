### è€ƒæ ¸äºŒ
---
> **æ•£ç‚¹å›¾**

![alt text](ä»»åŠ¡1ï¼.png)

ï¼ˆæœ€å¼€å§‹æ–­æ–­ç»­ç»­çœ‹å´æ©è¾¾çš„è§†é¢‘ï¼ŒæŒ‰é¡ºåºçœ‹äº†30å¤šä¸ªï¼Œç„¶ååŠ ä¸Šæ”¾å‡ï¼Œæ‡ˆæ€ äº†è®¸å¤šâ•¥ï¹â•¥...ï¼Œæ‰€ä»¥è¾ƒæ™šæ‰ç»§ç»­è€ƒæ ¸äºŒå—¯~ o(*ï¿£â–½ï¿£*)oï¼‰

ï¼ˆçœŸæ­£å¼€å§‹ï¼Œé‡åˆ°çš„ç¬¬ä¸€ä¸ªé—®é¢˜å°±æ˜¯æ²¡è½¬æ¢æ•°æ®ç±»å‹ï¼Œåœ¨pytorchè¡¡é‡æ•°æ®ç»´åº¦çš„æ˜¯å¼ é‡tensorï¼›åœ¨æ­ç§¯æœ¨çš„æ—¶å€™ï¼Œæ²¡å¤ªæ³¨æ„å¤§å°å†™ï¼Œç„¶åå®ƒè€æ˜¯è­¦å‘Šï¼›æˆ‘è¿˜æ˜¯åˆ†äº†80%è®­ç»ƒé›†å’Œ20%éªŒè¯é›†ï¼›æˆ‘æ­ï¼Œå¯èƒ½æ˜¯å› ä¸ºæˆ‘åªç”¨äº†ä¸€å±‚ï¼Œç„¶åæ•°æ®æœ¬æ¥ä¹Ÿå°‘ï¼Œåˆšå¼€å§‹çš„å‡†ç¡®ç‡åªæœ‰0.58ï¼Œå°±æƒ³ç€æ€ä¹ˆä¼˜åŒ–ï¼‰

```python
import torch
import pandas as pd
import torch.nn as nn
from sklearn.model_selection import train_test_split

# è¯»å–CSVæ–‡ä»¶
data = pd.read_csv("D:\\æ¡Œé¢\\ç”°å­—å‹æ•£ç‚¹.csv", header=None)
data = pd.DataFrame(data)

# æå–ç‰¹å¾å’Œæ ‡ç­¾
X = torch.tensor(data.iloc[0:2, :].values, dtype=torch.float32)
labels = torch.tensor(data.iloc[2, :].values, dtype=torch.float32)

# å®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹
class SimpleLinearModel(nn.Module):
    def __init__(self):
        super(SimpleLinearModel, self).__init__()
        self.linear = nn.Linear(2, 1)  # è¾“å…¥ç‰¹å¾ç»´åº¦ä¸º2ï¼Œè¾“å‡ºç»´åº¦ä¸º1

    def forward(self, x):
        return torch.sigmoid(self.linear(x))

# åˆå§‹åŒ–æ¨¡å‹
model = SimpleLinearModel()

# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.BCELoss()  # äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X.T, labels, test_size=0.2, random_state=42)

# è®­ç»ƒæ¨¡å‹
num_epochs = 10000
for epoch in range(num_epochs):
    # å‰å‘ä¼ æ’­
    outputs = model(X_train)
    loss = criterion(outputs, y_train.view(-1, 1))  # view(-1, 1)å°†æ ‡ç­¾å½¢çŠ¶è°ƒæ•´ä¸ºåˆ—å‘é‡

    # åå‘ä¼ æ’­å’Œä¼˜åŒ–
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # æ‰“å°è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±
    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

# æµ‹è¯•æ¨¡å‹
with torch.no_grad():
    outputs = model(X_test)
    predicted_labels = torch.round(outputs)
    accuracy = (predicted_labels == y_test.view(-1, 1)).sum().item() / y_test.size(0)
    print(f'Test Accuracy: {accuracy:.2f}')
```
![alt text](image-5.png)ï¼ˆæ²¡ç»·ä½ï¼‰

å»æœäº†ä¸€ä¸‹ï¼Œå¯ä»¥

1. **è°ƒæ•´å­¦ä¹ ç‡ï¼š** å°è¯•ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡ï¼Œå¯èƒ½è¾ƒå°çš„å­¦ä¹ ç‡ä¼šæ›´å¥½åœ°æ”¶æ•›ã€‚æ‚¨å¯ä»¥å°è¯•å‡å°å­¦ä¹ ç‡å¹¶è§‚å¯Ÿæ¨¡å‹çš„æ€§èƒ½æ˜¯å¦æœ‰æ‰€æ”¹å–„ã€‚**ï¼ˆè¯•äº†ï¼Œ0.01æ”¹æˆ0.001ï¼Œå‡†ç¡®ç‡0.64äº†å“ˆå“ˆï¼‰**

2. **å¢åŠ è®­ç»ƒå‘¨æœŸæ•°ï¼š** å¯èƒ½éœ€è¦å¢åŠ è®­ç»ƒå‘¨æœŸæ•°ï¼Œä½¿æ¨¡å‹æœ‰æ›´å¤šçš„æ—¶é—´å­¦ä¹ æ•°æ®çš„æ¨¡å¼å’Œç‰¹å¾ã€‚æ‚¨å¯ä»¥å°è¯•å¢åŠ  `num_epochs` çš„å€¼å¹¶é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚**ï¼ˆæ”¹äº†ä¸ª100000ï¼Œæ€ä¹ˆåˆå˜å›0.58äº†ï¼‰**

3. **è°ƒæ•´ä¼˜åŒ–å™¨ï¼š** å°è¯•ä½¿ç”¨å…¶ä»–ä¼˜åŒ–å™¨ï¼Œå¦‚ Adam æˆ– RMSpropï¼Œè¿™äº›ä¼˜åŒ–å™¨é€šå¸¸å…·æœ‰æ›´å¥½çš„æ€§èƒ½å’Œæ”¶æ•›é€Ÿåº¦ã€‚**ï¼ˆç”¨äº†adamï¼Œå®ƒä¹Ÿé€‚åˆäºŒåˆ†ç±»é—®é¢˜ï¼Œä½†è¿˜æ˜¯0.58ï¼‰**

4. **æ­£åˆ™åŒ–ï¼š** æ·»åŠ æ­£åˆ™åŒ–é¡¹æ¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œä¾‹å¦‚ L1 æ­£åˆ™åŒ–æˆ– L2 æ­£åˆ™åŒ–ã€‚è¿™å¯ä»¥é€šè¿‡åœ¨ä¼˜åŒ–å™¨ä¸­è®¾ç½®æƒé‡è¡°å‡å‚æ•°æ¥å®ç°ã€‚ï¼ˆè·³è¿‡ï¼‰

5. **æ•°æ®é¢„å¤„ç†ï¼š** æ£€æŸ¥æ•°æ®æ˜¯å¦éœ€è¦è¿›è¡Œæ ‡å‡†åŒ–æˆ–å½’ä¸€åŒ–å¤„ç†ï¼Œä»¥åŠæ˜¯å¦å­˜åœ¨ç¼ºå¤±å€¼éœ€è¦å¤„ç†ã€‚ï¼ˆè·³è¿‡ï¼‰

6. **æ¨¡å‹è°ƒå‚ï¼š** è°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°ï¼Œå¦‚éšè—å±‚ç»´åº¦ã€å­¦ä¹ ç‡ã€æ­£åˆ™åŒ–ç³»æ•°ç­‰ã€‚ï¼ˆjumpï¼‰

7. **ç‰¹å¾å·¥ç¨‹ï¼š** è€ƒè™‘æ·»åŠ æ›´å¤šçš„ç‰¹å¾æˆ–å¯¹ç°æœ‰ç‰¹å¾è¿›è¡Œè½¬æ¢ï¼Œä»¥æé«˜æ¨¡å‹çš„è¡¨ç°ã€‚ï¼ˆjumpï¼‰

8. **æ¨¡å‹ç»“æ„ï¼š** è€ƒè™‘å°è¯•æ›´å¤æ‚çš„æ¨¡å‹ç»“æ„ï¼Œä¾‹å¦‚æ·»åŠ æ›´å¤šçš„éšè—å±‚æˆ–å¢åŠ éšè—å•å…ƒçš„æ•°é‡ã€‚ï¼ˆè®©æˆ‘è¯•è¯•ï¼‰

```python
import torch
import pandas as pd
import torch.nn as nn
from sklearn.model_selection import train_test_split

# è¯»å–CSVæ–‡ä»¶
data = pd.read_csv("D:\\æ¡Œé¢\\ç”°å­—å‹æ•£ç‚¹.csv", header=None)
data = pd.DataFrame(data)

# æå–ç‰¹å¾å’Œæ ‡ç­¾
X = torch.tensor(data.iloc[0:2, :].values, dtype=torch.float32)
labels = torch.tensor(data.iloc[2, :].values, dtype=torch.float32)

# å®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.linear1 = nn.Linear(2, 64)  # è¾“å…¥ç‰¹å¾ç»´åº¦ä¸º2ï¼Œéšè—å±‚ç»´åº¦ä¸º64
        self.linear2 = nn.Linear(64, 1)   # éšè—å±‚ç»´åº¦ä¸º64ï¼Œè¾“å‡ºç»´åº¦ä¸º1
        self.relu = nn.ReLU()             # ä½¿ç”¨ReLUä½œä¸ºæ¿€æ´»å‡½æ•°

    def forward(self, x):
        x = self.relu(self.linear1(x))
        return torch.sigmoid(self.linear2(x))

# å®ä¾‹åŒ–æ¨¡å‹
model = SimpleModel()

# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.BCELoss()  # äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°
optimizer = torch.optim.Adam(model.parameters(), lr=0.001) 

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X.T, labels, test_size=0.2, random_state=42)

# è®­ç»ƒæ¨¡å‹
num_epochs = 1000
for epoch in range(num_epochs):
    # å‰å‘ä¼ æ’­
    outputs = model(X_train)
    loss = criterion(outputs, y_train.view(-1, 1))  # view(-1, 1)å°†æ ‡ç­¾å½¢çŠ¶è°ƒæ•´ä¸ºåˆ—å‘é‡

    # åå‘ä¼ æ’­å’Œä¼˜åŒ–
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # æ‰“å°è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±
    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

# æµ‹è¯•æ¨¡å‹
with torch.no_grad():
    outputs = model(X_test)
    predicted_labels = torch.round(outputs)
    accuracy = (predicted_labels == y_test.view(-1, 1)).sum().item() / y_test.size(0)
    print(f'Test Accuracy: {accuracy:.2f}')
```
![alt text](image-6.png)
ç»ˆäºä¸Š9äº†ï¼Œåœ¨ä¸€ç³»åˆ—å‘ƒï¼Œæ¢äº†ä¸ªä¼˜åŒ–å™¨ï¼Œæ·»åŠ äº†ä¸€ä¸ªéšè—å±‚ï¼Œepochä¸º1000ï¼Œ10000æ—¶1.00äº†ï¼Œ/(ã„’oã„’)/~~

![alt text](image-7.png)(âŠ™ï¹âŠ™)
![alt text](image-8.png)
lrä¸º0.1æ—¶
åé¢losså€¼éƒ½0.00å¥½ä¹…äº†ï¼Œæ€ä¹ˆå‡†ç¡®ç‡è¿˜æ˜¯0.97(:thinking:)
ï¼ˆå‘ƒï¼Œå› ä¸ºè¶…çº§æ™šäº¤è€ƒæ ¸äºŒï¼Œè‡ªé—®è‡ªç­”ä¸€æ³¢ï¼Œå‘ƒtest accuracyæŒ‰çš„æ˜¯å¹³å‡lossï¼‰

> å¹²è±†ï¼(âŠ™ï¹âŠ™)ï¼Œå…ˆå¤šæå‡ ä¸ªéšè—å±‚å…ˆï¼Œå¢åŠ æ·±åº¦ï¼Œå†å¤šæå‡ ä¸ªç¥ç»å…ƒæ¬¸å˜¿å˜¿
noticeï¼šæ•°æ®é›†ç›´æ¥è½¬ä¸ºå¼ é‡æ•°æ®é›†ï¼Œä¸ç”¨ä¸€åˆ—ä¸€åˆ—æï¼Œä½†è¦æ„å»ºæ•°æ®åŠ è½½å™¨
```python
import torch
import pandas as pd
import torch.nn as nn
from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset, DataLoader

# è¯»å–æ•°æ®
data = pd.read_csv("D:\\æ¡Œé¢\\gandou.csv")

# æå–ç‰¹å¾å’Œæ ‡ç­¾
X = data.iloc[:, :-1].values  # æå–ç‰¹å¾
y = data.iloc[:, -1].values  # æå–æ ‡ç­¾

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# è½¬æ¢ä¸ºå¼ é‡æ•°æ®é›†
train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))
test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))

# æ„å»ºæ•°æ®åŠ è½½å™¨
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64)
# å®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹
class SimpleLinearModel(nn.Module):
    def __init__(self):
        super(SimpleLinearModel, self).__init__()
        self.fc1 = nn.Linear(16, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 64)
        self.fc4 = nn.Linear(64, 4)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = self.fc4(x)
        return x

# å®ä¾‹åŒ–æ¨¡å‹
model = SimpleLinearModel()

# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.CrossEntropyLoss()# é€‚ç”¨äºå¤šåˆ†ç±»çš„äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ŒBCEæ˜¯é€‚ç”¨äºäºŒåˆ†ç±»çš„äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# è®­ç»ƒæ¨¡å‹
num_epochs = 100
for epoch in range(num_epochs):
    model.train()
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

# æµ‹è¯•æ¨¡å‹
model.eval()
with torch.no_grad():
    correct = 0
    total = 0
    for inputs, labels in test_loader:
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    accuracy = correct / total
    print(f'Test Accuracy: {accuracy:.2f}')
```
![alt text](image-10.png)
epochæ”¹ä¸º1000ä¹Ÿä¸€æ ·ï¼Œå¥½æˆ‘å‡å°å­¦ä¹ ç‡ï¼Œå¥½ï¼Œæ²¡ç”¨ã€‚å—¯ï¼Œæ¢ä¸ªä¼˜åŒ–å™¨ï¼Œæ¢Adamï¼›å•Šä¸è¡Œï¼Œè¿˜32ï¼›ğŸ¤”ï¼Œçœ‹äº†ä¸€çœ¼æ•°æ®é›†å†…å®¹ï¼Œæ•°æ®ä¹‹é—´å› ä¸ºä¸åŒç±»å‹ï¼Œå¤§çš„æœ‰é¢ç§¯ï¼Œè¶…çº§å°çš„åˆæœ‰å½¢çŠ¶ï¼Œæ•°æ®é¢„å¤„ç†ğŸ¤”ï¼Œå¥½å¥½å¥½ï¼Œæ–‡æ¡£ä¸­å­¦é•¿ä¹Ÿè¯´äº†è¦æ•°æ®é¢„å¤„ç†/(ã„’oã„’)/~~

> æ•°æ®æ ‡å‡†åŒ–ï¼ˆStandardizationï¼‰ï¼š
å¯¹äºæ•°å€¼å‹ç‰¹å¾ï¼Œå¯ä»¥ä½¿ç”¨sklearn.preprocessing.StandardScalerè¿›è¡Œæ•°æ®æ ‡å‡†åŒ–å¤„ç†ï¼Œå°†ç‰¹å¾å€¼ç¼©æ”¾åˆ°å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„èŒƒå›´å†…ï¼Œä»¥æé«˜æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§ã€‚(â—Ë‡âˆ€Ë‡â—)

```python
from sklearn.preprocessing import StandardScaler
# æ•°æ®é¢„å¤„ç†
scaler = StandardScaler()
X = scaler.fit_transform(X)# åŠ äº†ä¸ªè¿™ä¸ªå˜¿å˜¿
  ```  
![alt text](image-11.png)
win!